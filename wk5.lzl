@ title Linear Algebra Worksheet 5
@ author Jonny Evans
@ date Workshop 5
@ include head

\setcounter{section}{5}

# Exercise exr:ellipsoid
  Consider the ellipsoid defined by the equation
  \[2(x^2+y^2+z^2-xy-yz)=1.\] Write this equation in the form
  \(v^TAv=1\) for \(v=\ma x\\y\\z\mz\) and some matrix \(A\). Find the
  eigenvalues of \(A\) and check they are all positive. Find the
  principal directions and principal radii of this ellipsoid. (Hint:
  Recall from lectures that if the ellipsoid is cut out by the
  equation \(v^TAv=1\) then the principal directions are the
  eigendirections for \(A\) and the principal radii are
  \(1/\sqrt{\lambda}\) for the corresponding eigenvalues \(\lambda\).)

# Exercise
  Let \(a,b\) be two numbers and consider the matrix \(M=\ma a & b
  \\ b & a \mz\). What are the eigenvalues and eigenvectors of this
  matrix? Suppose that \(a+b>1\) and \(1>a-b>0\). What happens to the
  vectors \(M^n\ma 1 \\ 0\mz\) and \(M^n\ma 0 \\ 1\mz\) as
  \(n\to\infty\)?

# Exercise
  Find the kernel and nullity for each of the following matrices
  \[A=\ma 1 & 0 & 7 \\ 4 & 2 & 1\\ 3 & 2 & -6\mz,\quad B=\ma 2 & 3 & 0
  & 1 \\ 1 & 0 & 2 & 0\mz,\quad C=\ma 1 & 0 & -1\mz.\]
  What is the rank in each case?

# Exercise exr:hermitian
  We say that a complex matrix \(A\) is {\em Hermitian} if
  \(\bar{A}^T=A\) (here the bar means complex conjugation of each
  matrix entry). Show that any eigenvalue of a Hermitian matrix is
  real and that if \(v\) and \(w\) are eigenvectors for distinct
  eigenvalues \(\lambda\neq\mu\) then \(\bar{v}^Tw=0\). {\em These
  observations are important in quantum mechanics, because eigenvalues
  of Hermitian operators are what we measure as observable quantities
  like energy.}

# Exercise
  Find the limit \(\lim_{n\to\infty}\frac{P_{n+1}}{P_n}\) where
  \(P_n\) is the sequence of Pell numbers (defined by the recurrence
  \(P_{n+2}=2P_{n+1}+P_n\), \(P_1=0\), \(P_2=1\)).


# Exercise exr:companion
  Find the characteristic polynomials of the matrices: \[\ma 0 & -c_0
  \\ 1 & -c_1\mz,\quad\ma 0 & 0 & -c_0 \\ 1 & 0 & -c_1 \\ 0 & 1 &
  -c_2\mz,\quad\ma 0 & 0 & 0 & -c_0 \\ 1 & 0 & 0 & -c_1 \\ 0 & 1 & 0 &
  -c_2 \\ 0 & 0 & 1 & -c_3\mz.\] Have a guess at the characteristic
  polynomial of
  \[\ma 0 & 0 & \cdots & 0 & -c_0 \\ 1 & \ddots & \ddots & \vdots &
  \vdots\\ 0 & \ddots & \ddots & 0 & -c_{n-3} \\ \vdots & \ddots & 1 &
  0 & -c_{n-2} \\ 0 & \cdots & 0 & 1 & -c_{n-1}\mz.\] Prove your
  guess by induction.

# Exercise exr:companionrevisited
  Solve \cref{exr:companion} using as many different methods to
  compute determinants as you can.


\newpage

* Challenge problems

# Exercise exr:vandermonde
  Given numbers \(\lambda_1,\ldots,\lambda_n\), the matrix \[V=\ma 1 &
  \lambda_1 & \lambda_1^2 & \cdots & \lambda_1^{n-1} \\ 1 & \lambda_2
  & \lambda_2^2 & \cdots & \lambda_2^{n-1} \\ \vdots & \vdots & &
  \vdots \\ 1 & \lambda_n & \lambda_n^2 & \cdots & \lambda_n^{n-1}
  \mz\] is called the {\em Vandermonde matrix}. Consider the quantity
  \[Q=\prod_{1\leq i<j\leq n}(\lambda_j-\lambda_i)\] (for example, if
  \(n=3\),
  \(Q=(\lambda_3-\lambda_2)(\lambda_3-\lambda_1)(\lambda_2-\lambda_1)\)). Verify
  that \(\det(V)=Q\) for \(n=2\) and \(n=3\). Show that both
  \(\det(V)\) and \(Q\) vanish if \(\lambda_k=\lambda_\ell\) for some
  \(k\neq \ell\).

  {\em In fact, \(\det(V)=Q\) for all \(n\).}
# Exercise exr:companionrerevisited
  Let \(C=\ma 0 & 0 & \cdots & 0 & -c_0 \\ 1 & \ddots & \ddots &
  \vdots & \vdots\\ 0 & \ddots & \ddots & 0 & -c_{n-3} \\ \vdots &
  \ddots & 1 & 0 & -c_{n-2} \\ 0 & \cdots & 0 & 1 & -c_{n-1}\mz\),
  (see \cref{exr:companion} for its characteristic polynomial!). Show
  that if \(\lambda\) is an eigenvalue of \(C\) then the row vector
  \(w=\ma 1 & \lambda & \lambda^2 & \cdots & \lambda^{n-1}\mz\)
  satisfies \(wC=\lambda w\). Deduce that if \(C\) has distinct
  eigenvalues \(\lambda_1,\ldots,\lambda_n\) and \(V\) is the
  Vandermonde matrix from \cref{exr:vandermonde} whose \(i\)th row is
  \(\ma 1 & \lambda_i & \lambda_i^2 & \cdots & \lambda_i^{n-1}\mz\)
  then \(VCV^{-1}\) is the diagonal matrix \(\ma \lambda_1 & & \\ &
  \ddots & \\ & & \lambda_n\mz\).  Hence prove that
  \(Tr(C^m)=\sum_{i=1}^n\lambda_i^m\) for all \(m\).

# Exercise exr:coeffs
  If \(t^n+c_{n-1}t^{n-1}+\cdots+c_0\) is a polynomial of degree \(n\)
  with leading coefficient \(1\) and distinct roots, show that the sum
  of squares of its roots is \(c_{n-1}^2-2c_{n-2}\) and find a similar
  expression for the sum of cubes of the roots. (Hint: Use
  \cref{exr:companionrerevisited})
  
# Exercise
  Given a polynomial \(p(z)=p_mz^m+\cdots+p_0\) of degree \(m\) and a
  polynomial \(q(z)=q_nz^n+\cdots+q_0\) of degree \(n\), the {\em
  resultant} of \(p\) and \(q\) is defined to be the determinant of
  the \((m+n)\)-by-\((m+n)\) matrix \[\ma p_m & p_{m-1} & \cdots & p_1
  & p_0 & 0 & 0 & \cdots & 0 \\ 0 & p_m & p_{m-1} & \cdots & p_1 & p_0
  & 0 & \ddots & \vdots \\ 0 & 0 & p_m & p_{m-1} & \cdots & p_1 & p_0
  & \ddots & 0 \\ \vdots & \vdots & \ddots & \ddots & \ddots & & &
  \ddots & 0 \\ 0 & \cdots & \cdots & 0 & p_m & p_{m-1} & \cdots & p_1
  & p_0 \\ q_n & q_{n-1} & \cdots & q_0 & 0 & 0 & 0 & \cdots & 0 \\ 0
  & q_m & q_{m-1} & \cdots & q_0 & 0 & 0 & \ddots & \vdots \\ 0 & 0 &
  q_m & q_{m-1} & \cdots & q_0 & 0 & \ddots & 0 \\ \vdots & \vdots &
  \ddots & \ddots & \ddots & & & \ddots & \vdots
  \\ \vdots&&&&&\ddots&&\ddots&0\\ 0 & \cdots & \cdots & 0 & 0 & q_m &
  q_{m-1} & \cdots & q_0 \mz\] It is a theorem of Sylvester that the
  resultant of \(p\) and \(q\) vanishes if and only if \(p\) and \(q\)
  have a common factor.

  Write this matrix out in the case when \(m=2\), \(n=1\) and verify
  that the resultant vanishes if and only if there exists a polynomial
  \(a+bz\) such that \(p(z)=q(z)(a+bz)\)).

\newpage

* Solutions

# Solution
  The ellipsoid equation can be written as \(v^TAv=1\) for \[A=\ma 2 &
  -1 & 0 \\ -1 & 2 & -1 \\ 0 & -1 & 2\mz.\] The eigenvalues of \(A\)
  are the solutions to \(\det(A-tI)=0\), i.e. \(2,2\pm\sqrt{2}\). The
  eigenvectors are \(\ma 1 \\ 0 \\ -1\mz\), \(\ma 1 \\ \mp\sqrt{2}
  \\ 1\mz\): these are the principal directions. The principal radii
  are \(\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2\pm\sqrt{2}}}\).

# Solution
  The eigenvalues of \(\ma a & b \\ b & a\mz\) are the solutions of
  \((a-t)^2-b^2=0\), i.e. \(t^2-2at+a^2-b^2=0\). These solutions are
  \(\frac{2a\pm\sqrt{4a^2-4a^2+4b^2}}{2}=a\pm b\). The corresponding
  eigenvectors are the solutions of
  \begin{align*}
  ax+by&=(a\pm b)x\\
  bx+ay&=(a\pm b)y,
  \end{align*}
  which means \(y=\pm x\). Therefore the eigenvectors are multiples of
  \(\ma 1 \\ \pm 1\mz\).

  We have \(\ma 1 \\ 0 \mz=\frac{1}{2}\ma 1 \\ 1\mz+\frac{1}{2}\ma 1
  \\ -1\mz\), so \[M^n\ma 1 \\ 0\mz=\frac{1}{2}M^n\ma 1 \\ 1
  \mz+\frac{1}{2}M^n\ma 1 \\ -1\mz=\frac{1}{2}(a+b)^n\ma 1
  \\ 1\mz+\frac{1}{2}(a-b)^n\ma 1 \\ -1\mz,\] so \(M^n\ma 1 \\ 0 \mz\)
  gets closer and closer to the line \(y=x\) as \(n\to\infty\)
  (because \((a+b)^n\to\infty\) as \(a+b>1\) and \((a-b)^n\to 0\) as
  \(0<a-b<1\); see the red vectors in the figure below). Similarly
  \(M^n\ma 0 \\ 1\mz\) gets closer to this line (blue vectors in the
  figure below).

  \tka
  \draw[->,thick] (0,0) -- (2,2);
  \draw[->,thick] (0,0) -- (2,-2);
  \draw[->,red] (0,0) -- (2,0);
  \draw[->,red] (0,0) -- (4,2);
  \draw[->,red] (0,0) -- (10/2,8/2);
  \draw[dotted,red] (10/2,8/2) -- (10/1.7,8/1.7);
  \draw[->,red] (0,0) -- (14/3,13/3);
  \draw[dotted,red] (14/3,13/3) -- (14/2.5,13/2.5);
  \draw[->,blue] (0,0) -- (0,2);
  \draw[->,blue] (0,0) -- (2,4);
  \draw[->,blue] (0,0) -- (8/2,10/2);
  \draw[dotted,blue] (8/2,10/2) -- (8/1.7,10/1.7);
  \draw[->,blue] (0,0) -- (13/3,14/3);
  \draw[dotted,blue] (13/3,14/3) -- (13/2.5,14/2.5);
  \tkz

# Solution
  The equation \(Av=0\) is
  \begin{align*}
  x+7z&=0\\
  4x+2y+z&=0\\
  3x+2y-6z&=0
  \end{align*}
  which has solution \(x=-7z\), \(y=27z/2\), so the kernel consists of
  vectors of the form \(\ma -7z \\ 27z/2 \\ z\mz\). The nullity is 1
  in this instance. By the rank-nullity theorem, the rank is 2.

  The equation \(Bv=0\) is
  \begin{align*}
  2x+3y+w&=0\\
  x+2z&=0,
  \end{align*}
  which has solution \(x=-2z\), \(w=4z-3y\), so the kernel consists of
  vectors of the form \(\ma -2z \\ y \\ z \\ 4z-3y\mz\). The nullity
  is 2 in this instance. By the rank-nullity theorem, the rank is 2.

  The equation \(Cv=0\) is
  \[x-z=0,\]
  which has solution \(z=x\), so the kernel consists of vectors of the
  form \(\ma x \\ y \\ x\mz\). The nullity in this instance is 2. By
  the rank-nullity theorem, the rank is 1.

# Solution sol:exr:hermitian Solution to \cref{exr:hermitian}
  Suppose that \(Av=\lambda v\). Consider the expression
  \(\bar{v}^TAv\), where \(\bar{v}\) denotes complex
  conjugation. Then, because \(A=\bar{A}^T\), we have
  \[\bar{\lambda}\bar{v}^Tv=(\overline{Av})^{T}v=\bar{v}^TAv=\lambda\bar{v}^Tv.\]
  Note that if \(v=\ma x_1\\ \vdots\\ x_n\mz\) then
  \(\bar{v}^Tv=\sum |x_1|^2+\cdots+|x_n|^2>0\) if \(v\neq 0\), so
  dividing through by \(\bar{v}^Tv\) we get \(\bar{\lambda}=\lambda\)
  and deduce that \(\lambda\) is real.

  If \(v\) and \(w\) are two eigenvectors for distinct eigenvalues
  \(\lambda,\mu\) then
  \begin{align*}
  \lambda \bar{w}^Tv&=\bar{w}^T(Av)\\
  &=\overline{(Aw)}^Tv\\
  &=\mu \bar{w}^Tv\\
  \end{align*}
  (since \(\bar{\mu}=\mu\) by the first part) so, since
  \(\lambda\neq\mu\), we must have \(\bar{w}^Tv=0\). \qedhere

# Solution
  The Pell numbers satisfy \[\ma P_{n+2} \\ P_{n+1}\mz=\ma 0 & 1 \\ 1
  & 2\mz\ma P_{n+1} \\ P_n\mz.\] (Let's write \(M\) for the matrix in
  this expression). The eigenvalues of \(M\) are the solutions of
  \(0=\det(M-tI)\), i.e. \[0=-t(2-t)-1=t^2-2t-1,\] which are
  \(\frac{2\pm\sqrt{4+4}}{2}=1\pm\sqrt{2}\). The eigenvectors are
  \(\ma 1 \\ 1\pm\sqrt{2}\mz\). This means that
  \(\lim_{n\to\infty}\frac{P_{n+1}}{P_n}=1+\sqrt{2}\) (by the same
  argument that we used for the Fibonacci numbers in lectures).

# Solution
  We have
  \begin{align*}
  \det\ma -t & -c_0 \\ 1 & -c_1-t\mz=t^2+c_1t+c_0\\
  \det\ma -t & 0 & -c_0 \\ 1 & -t & -c_1 \\ 0 & 1 & -c_2-t\mz&=-(t^3+c_2t^2+c_1t+c_0)\\
  \det\ma -t & 0 & 0 & -c_0 \\ 1 & -t & 0 & -c_1 \\ 0 & 1 & -t & -c_2 \\ 0 & 0 & 1 & -c_3-t\mz&=t^4+c_3t^3+c_2t^2+c_1t+c_0.
  \end{align*}
  More generally, we have \[\det\ma -t & 0 & \cdots & 0 & -c_0 \\ 1 &
  \ddots & \ddots & \vdots & \vdots\\ 0 & \ddots & \ddots & 0 &
  -c_{n-3} \\ \vdots & \ddots & 1 & -t & -c_{n-2} \\ 0 & \cdots & 0 &
  1 & -c_{n-1}-t\mz=(-1)^n(t^n+c_{n-1}t^{n-1}+\cdots+c_0).\] To prove
  this by induction, assume it's true for \(n-1\) and let's evaluate
  the determinant \[D_n:=\det\ma -t & 0 & \cdots & 0 & -c_0 \\ 1 &
  \ddots & \ddots & \vdots & \vdots\\ 0 & \ddots & \ddots & 0 &
  -c_{n-3} \\ \vdots & \ddots & 1 & -t & -c_{n-2} \\ 0 & \cdots & 0 &
  1 & -c_{n-1}-t\mz.\] Expanding along the first column, we get
  \[-tD_{n-1}-\det\ma 0 & \cdots & \cdots & 0 & -c_0 \\ 1 & -t & & 0 &
  -c_1 \\ 0 & 1 & \ddots & & \vdots \\ \vdots & \ddots & \ddots & -t &
  -c_{n-2} \\ 0 & \cdots & 0 & 1 & -c_{n-1}-t\mz\] We evaluate this
  final determinant as follows: pick \(c_0\) from the top row
  (everything else is zero); pick either \(1\) or \(-t\) from the
  second row; if you picked \(1\) you can pick either \(1\) or \(-t\)
  from the third row whereas if you picked \(-t\) you have to pick
  \(-t\) from the third row; continue in this manner and you either
  pick all the \(1\)s or else you pick \(-t\) until you reach the last
  row and you're forced to pick a zero. Therefore the only term we get
  is \(c_0\) (with a sign). The sign is \((-1)^{n+1}\) as we can see
  because this permutation is \((123\cdots n)\). Therefore
  \[D_n=-tD_{n-1}-(-1)^{n+1}c_0=(-1)^n(t^n+c_{n-1}t^{n-1}+\cdots+c_0)\]
  by inductive hypothesis (i.e. substituting in what we assumed was
  the formula for \(D_{n-1}\)). We already checked the base case
  \(D_2\), so we're done.

* Solutions to challenge problems

# Solution
  We have \[\det\ma 1 & \lambda_1 \\ 1 &
  \lambda_2\mz=\lambda_2-\lambda_2.\] Next: \[\det\ma 1 & \lambda_1 &
  \lambda_1^2 \\ 1 & \lambda_2 & \lambda_2^2 \\ 1 & \lambda_3 &
  \lambda_3^2\mz=\lambda_2\lambda_3^2-\lambda_2^2\lambda_3-\lambda_1(\lambda_3^2-\lambda_2^2)+\lambda_1^2(\lambda_3-\lambda_2)\]
  i.e. \(\lambda_2\lambda_3(\lambda_3-\lambda_2)-\lambda_1(\lambda_3-\lambda_2)(\lambda_3+\lambda_2)+\lambda_1^2(\lambda_3-\lambda_2)\),
  so we can pull out a factor of \(\lambda_3-\lambda_2\), leaving
  \[\lambda_2\lambda_3-\lambda_1\lambda_3-\lambda_1\lambda_2+\lambda_1^2=(\lambda_3-\lambda_1)(\lambda_2-\lambda_1)\]
  and again we get \(\det(V)=Q\) as required.

  If \(\lambda_k=\lambda_{\ell}\) then the Vandermonde determinant
  vanishes (two rows coincide) and the expression \(Q\) vanishes
  (because \(\lambda_k-\lambda_{\ell}\) is a factor.

# Solution
  We saw that the characteristic polynomial of \(C\) is
  \(\pm(t^n+c_{n-1}t^{n-1}+\cdots+c_1t+c_0\), so the eigenvalues of
  \(C\) are the roots \(\lambda_1,\ldots,\lambda_n\) of this
  polynomial. If we form the corresponding Vandermonde matrix whose
  \(i\)th row is given by powers of \(\lambda_i\) then we see that
  \begin{align*}\ma 1 & \lambda_i & \lambda_i^2 &\cdots
  &\lambda_i^{n-1}\mz C&=\ma \lambda_i & \lambda_i^2 & \cdots &
  \lambda_i^{n-1} &
  -c_0-c_1\lambda_i-\cdots-c_{n-1}\lambda_i^{n-1}\mz\\
  &=\ma \lambda_i & \lambda_i^2 & \cdots & \lambda_i^{n-1} &
  \lambda_i^n\mz\\
  &=\lambda\ma 1 & \lambda & \cdots &\lambda^{n-1}\mz.\end{align*}
  Therefore the \(i\)th row of \(VC\) is \(\lambda_i\) times the
  \(i\)th row of \(V\). Let \(R_i\) be the \(i\)th row of \(V\) and
  \(C_i\) be the \(i\)th columns of \(V^{-1}\) (so
  \(R_iC_j=\delta_{ij}\)). Then \(VC\) has rows \(\lambda_i R_i\), so
  the \(ij\) entry of \(VCV^{-1}\) is
  \(\lambda_iR_iC_j=\lambda_i\delta_{ij}\), and we see that
  \(VCV^{-1}\) is the diagonal matrix with
  \(\lambda_1,\ldots,\lambda_n\) down the diagonal.

  We know that
  \(\mathrm{Tr}((VCV^{-1})^m)=\mathrm{Tr}(VC^mV^{-1})=\mathrm{Tr}(V^{-1}VC^m)=\mathrm{Tr}(C^m)\)
  because \(\mathrm{Tr}(AB)=\mathrm{Tr}(BA)\) from sheet 1. Therefore
  \(\mathrm{Tr}(C^m)=\mathrm{Tr}(diag(\lambda_1^m,\ldots,\lambda_n^m))=\sum\lambda_i^m\).

# Solution
  By the previous question, we know that the sum of squares of the
  roots of this polynomial is \(\mathrm{Tr}(C^2)\). The only nonzero
  diagonal entries of \(C^2\) are the final two, which are
  \(-c_{n-2}\) and \(c_{n-1}^2-c_{n-2}\), so we get
  \(c_{n-1}^2-2c_{n-2}\) as required. For the sum of cubes, we compute
  \(\mathrm{Tr}(C^3)\) and we get
  \(-c_{n-1}^3+3c_{n-2}c_{n-1}-3c_{n-3}\).

# Solution
  In the case \(m=2,n=1\) the Sylvester matrix is
  \[\ma p_2 & p_1 & p_0 \\ q_1 & q_0 & 0 \\ 0 & q_1 & q_0\mz,\]
  whose determinant is \(p_2q_0^2-p_1q_1q_0+p_0q_1^2\).

  If there exist \(a,b\) such that \(p=(a+bz)q\) then \[p_2=bq_1,\quad
  p_1=aq_1+bq_0,\quad p_0=aq_0,\] so the determinant is
  \[bq_1q_0^2-(aq_1+bq_0)q_1q_0+aq_0q_1^2=0.\] Conversely, suppose
  that \(p_2q_0^2-p_1q_1q_0+p_0q_1^2=0\). Note that \(q_1\neq 0\) or
  else \(q\) has degree less than \(1\).
  - If \(q_0=0\) then \(p_0q_1^2=0\), so \(p_0=0\) and
    \(z|p(z)\). Since \(q_0=0\), \(q(z)=q_1z\), so \(z|q(z)\) and we
    have found a common factor.
  - if \(q_0\neq 0\) then consider the polynomial
    \((p_2/q_1)z+(p_0/q_0)\). We have
    \[(p_2/q_1)z+(p_0/q_0)(q_1z+q_0)=p_2z^2+\left(\frac{p_2q_0}{q_1}+\frac{p_0q_1}{q_0}\right)+p_0\]
    and the term in brackets is equal to \(p_1\) because
    \(p_2q_0^2+p_0q_1^2=p_1q_0q_1\). Therefore \(q\) is a common
    factor of \(p\) and \(q\).
